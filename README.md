# Convolution Approximations
This repository contains code to apply the approximations to weight tensors.    

## compress_conv

This folder contains matlab code to compute the decompositions described in the paper Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation.    
Corresponding paper available [here](https://arxiv.org/pdf/1404.0736v2.pdf).  Download code [here](https://cs.nyu.edu/~denton/).

Decomposition functions:
- monochromatic_approx.m
- bisubspace_lowrank_approx.m
- bisubspace_svd_example.lua

Examples of use:
- monochromatic_example.m
- bisubspace_lowrank_example.m
- bisubspace_svd_example.lua

Note that the approximation in the example scripts will be terrible since the weights are initialized to be random (out method relies on the structure inherent in trained convolutional network weights).

## dump_parser

Receives a textual representation of a flatbuffer (.tflite) generated by [neural-network-transpiler](https://gitlab.com/LEDLGroup/neural-network-transpiler.git) and converts it to a pickle file.    
With the pickle file it can reconstruct the flatbuffer or apply an approximation and then reconstruct the flatbuffer. 

### Requirements

- libmagic-dev
    - `sudo apt-get install libmagic-dev`
- python-libmagic
    - `pip install python-libmagic`

### Instructions

#### Dump flatbuffer weigths with nnt
- Compile [neural-network-transpiler](https://gitlab.com/LEDLGroup/neural-network-transpiler.git)
- Generate the weigths dump
    - `./nnt -w -m [MODEL.tflite] > out-nnt.txt`

#### Convert dump text to pickle file
- `./dump_parser out-nnt.txt`
- It will generate a .pkl file, for example 'out-nnt.pkl'

#### Rebuild flatbuffer from pickle file
- `./flatbuffer_rebuilder.py -m out-nnt.pkl`
- It will generate a .tflite file, for example 'reconstructed_out-nnt.tflite


## py_ver

Python implementation of matlab code in [compress_conv](./compress_conv).    
*Work in progress*




